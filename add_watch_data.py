#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™‚è¨ˆãƒ‡ãƒ¼ã‚¿è¿½åŠ çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
å‰å›ã®Tissotè¿½åŠ ã®åçœã‚’è¸ã¾ãˆã€å…¨å·¥ç¨‹ã‚’è‡ªå‹•åŒ–
"""

import pandas as pd
import sys
import os
import subprocess
import shutil
from datetime import datetime
from typing import Dict, Tuple
from generate_attributes import WatchAttributeGenerator

class WatchDataPipeline:
    """æ™‚è¨ˆãƒ‡ãƒ¼ã‚¿è¿½åŠ ã®çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""

    # æ—¢å­˜CSVãƒ‘ã‚¹
    EXISTING_CSV = '/Users/naokijodan/Desktop/watch-market-analysis/æ™‚è¨ˆãƒ‡ãƒ¼ã‚¿_åˆ†é¡æ¸ˆã¿.csv'
    TEMP_CSV = '/Users/naokijodan/Desktop/watch-market-analysis/æ™‚è¨ˆãƒ‡ãƒ¼ã‚¿_åˆ†é¡æ¸ˆã¿_temp.csv'
    BACKUP_CSV = '/Users/naokijodan/Desktop/watch-market-analysis/æ™‚è¨ˆãƒ‡ãƒ¼ã‚¿_åˆ†é¡æ¸ˆã¿_backup.csv'

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    PROJECT_DIR = '/Users/naokijodan/Desktop/watch-market-analysis'

    # é–¾å€¤è¨­å®š
    THRESHOLDS = {
        'é§†å‹•æ–¹å¼_åˆ¤å®šç‡_æœ€å°': 30.0,  # é§†å‹•æ–¹å¼ãŒ30%ä»¥ä¸Šåˆ¤å®šã§ãã¦ã„ã‚Œã°OK
        'ãƒ‡ãƒ‘ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆ_åˆ¤å®šç‡_æœ€å°': 20.0,  # ãƒ‡ãƒ‘ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆãŒ20%ä»¥ä¸Šåˆ¤å®šã§ãã¦ã„ã‚Œã°OK
        'æ­©ç•™ã¾ã‚Šç‡_æœ€å°': 20.0,  # å®Œå“ãƒ‡ãƒ¼ã‚¿ãŒ20%ä»¥ä¸Šã‚ã‚Œã°OK
    }

    def __init__(self, new_csv_path: str):
        """
        Args:
            new_csv_path: è¿½åŠ ã™ã‚‹æ–°è¦CSVã®ãƒ‘ã‚¹
        """
        self.new_csv_path = new_csv_path
        self.report = []  # è¨ºæ–­ãƒ¬ãƒãƒ¼ãƒˆ

    def log(self, message: str):
        """ãƒ­ã‚°å‡ºåŠ›"""
        print(message)
        self.report.append(message)

    def step1_dry_run(self) -> bool:
        """
        ã‚¹ãƒ†ãƒƒãƒ—1: Dry Runï¼ˆæŠ½å‡ºç‡ãƒã‚§ãƒƒã‚¯ï¼‰

        Returns:
            True: é–¾å€¤ã‚’ã‚¯ãƒªã‚¢, False: é–¾å€¤æœªé”
        """
        self.log("\n" + "="*80)
        self.log("ã‚¹ãƒ†ãƒƒãƒ—1: Dry Runï¼ˆæ–°è¦ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºç‡ãƒã‚§ãƒƒã‚¯ï¼‰")
        self.log("="*80)

        # æ–°è¦CSVã‚’èª­ã¿è¾¼ã¿
        try:
            df_new = pd.read_csv(self.new_csv_path)
            self.log(f"âœ“ æ–°è¦CSVèª­ã¿è¾¼ã¿: {len(df_new)}ä»¶")
        except Exception as e:
            self.log(f"âŒ ã‚¨ãƒ©ãƒ¼: CSVã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
            self.log(f"   {e}")
            return False

        # å±æ€§ã‚’ç”Ÿæˆï¼ˆãƒ†ã‚¹ãƒˆï¼‰
        self.log("\nğŸ”§ å±æ€§ç”Ÿæˆãƒ†ã‚¹ãƒˆä¸­...")
        df_with_attrs = WatchAttributeGenerator.generate_all_attributes(df_new)

        # æŠ½å‡ºç‡ã‚’è¨ˆç®—
        rates = WatchAttributeGenerator.calculate_extraction_rates(df_with_attrs)

        self.log("\nğŸ“Š æŠ½å‡ºç‡:")
        for attr, rate in rates.items():
            self.log(f"  {attr}: {rate:.1f}%")

        # é–¾å€¤ãƒã‚§ãƒƒã‚¯
        self.log("\nğŸ” é–¾å€¤ãƒã‚§ãƒƒã‚¯:")
        é§†å‹•æ–¹å¼_åˆ¤å®šç‡ = rates.get('é§†å‹•æ–¹å¼_åˆ¤å®šç‡', 0)
        ãƒ‡ãƒ‘ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆ_åˆ¤å®šç‡ = rates.get('ãƒ‡ãƒ‘ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆ_åˆ¤å®šç‡', 0)

        passed = True

        if é§†å‹•æ–¹å¼_åˆ¤å®šç‡ < self.THRESHOLDS['é§†å‹•æ–¹å¼_åˆ¤å®šç‡_æœ€å°']:
            self.log(f"  âš ï¸ é§†å‹•æ–¹å¼ã®åˆ¤å®šç‡ãŒä½ã„: {é§†å‹•æ–¹å¼_åˆ¤å®šç‡:.1f}% < {self.THRESHOLDS['é§†å‹•æ–¹å¼_åˆ¤å®šç‡_æœ€å°']}%")
            self.log("     â†’ ã‚¿ã‚¤ãƒˆãƒ«ã« 'Automatic', 'Quartz', 'Solar' ç­‰ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå°‘ãªã„å¯èƒ½æ€§")
            passed = False
        else:
            self.log(f"  âœ“ é§†å‹•æ–¹å¼åˆ¤å®šç‡: OK ({é§†å‹•æ–¹å¼_åˆ¤å®šç‡:.1f}%)")

        if ãƒ‡ãƒ‘ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆ_åˆ¤å®šç‡ < self.THRESHOLDS['ãƒ‡ãƒ‘ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆ_åˆ¤å®šç‡_æœ€å°']:
            self.log(f"  âš ï¸ ãƒ‡ãƒ‘ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã®åˆ¤å®šç‡ãŒä½ã„: {ãƒ‡ãƒ‘ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆ_åˆ¤å®šç‡:.1f}% < {self.THRESHOLDS['ãƒ‡ãƒ‘ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆ_åˆ¤å®šç‡_æœ€å°']}%")
            self.log("     â†’ ã‚¿ã‚¤ãƒˆãƒ«ã« 'Men', 'Women', 'Ladies' ç­‰ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå°‘ãªã„å¯èƒ½æ€§")
            passed = False
        else:
            self.log(f"  âœ“ ãƒ‡ãƒ‘ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆåˆ¤å®šç‡: OK ({ãƒ‡ãƒ‘ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆ_åˆ¤å®šç‡:.1f}%)")

        if not passed:
            self.log("\nâŒ Dry RunãŒé–¾å€¤æœªé”ã§ã™ã€‚æ–°è¦ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return False

        self.log("\nâœ… Dry RunæˆåŠŸï¼ˆå…¨é–¾å€¤ã‚¯ãƒªã‚¢ï¼‰")
        return True

    def step2_merge_csv(self) -> Tuple[bool, int, int]:
        """
        ã‚¹ãƒ†ãƒƒãƒ—2: CSVãƒãƒ¼ã‚¸ï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼‰

        Returns:
            (success, new_count, duplicate_count)
        """
        self.log("\n" + "="*80)
        self.log("ã‚¹ãƒ†ãƒƒãƒ—2: CSVãƒãƒ¼ã‚¸ï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼‰")
        self.log("="*80)

        # æ—¢å­˜CSVã‚’èª­ã¿è¾¼ã¿
        df_existing = pd.read_csv(self.EXISTING_CSV)
        self.log(f"âœ“ æ—¢å­˜CSV: {len(df_existing)}ä»¶")

        # æ–°è¦CSVã‚’èª­ã¿è¾¼ã¿
        df_new = pd.read_csv(self.new_csv_path)
        self.log(f"âœ“ æ–°è¦CSV: {len(df_new)}ä»¶")

        # å±æ€§ç”Ÿæˆ
        self.log("\nğŸ”§ æ–°è¦ãƒ‡ãƒ¼ã‚¿ã«å±æ€§ã‚’ç”Ÿæˆä¸­...")
        df_new_with_attrs = WatchAttributeGenerator.generate_all_attributes(df_new)

        # é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆã‚¿ã‚¤ãƒˆãƒ« + è²©å£²æ—¥ã§åˆ¤å®šï¼‰
        self.log("\nğŸ” é‡è¤‡ãƒã‚§ãƒƒã‚¯ä¸­...")
        df_merged = pd.concat([df_existing, df_new_with_attrs], ignore_index=True)

        # é‡è¤‡ã‚’å‰Šé™¤ï¼ˆã‚¿ã‚¤ãƒˆãƒ« + è²©å£²æ—¥ãŒåŒã˜ã‚‚ã®ã‚’å‰Šé™¤ï¼‰
        before_count = len(df_merged)
        df_merged = df_merged.drop_duplicates(subset=['ã‚¿ã‚¤ãƒˆãƒ«', 'è²©å£²æ—¥'], keep='first')
        after_count = len(df_merged)

        duplicate_count = before_count - after_count
        new_count = after_count - len(df_existing)

        self.log(f"  é‡è¤‡é™¤å¤–: {duplicate_count}ä»¶")
        self.log(f"  æ–°è¦è¿½åŠ : {new_count}ä»¶")
        self.log(f"  æœ€çµ‚ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {after_count}ä»¶")

        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        df_merged.to_csv(self.TEMP_CSV, index=False)
        self.log(f"\nâœ“ ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜: {self.TEMP_CSV}")

        return True, new_count, duplicate_count

    def step3_validate_yield_rate(self) -> bool:
        """
        ã‚¹ãƒ†ãƒƒãƒ—3: æ­©ç•™ã¾ã‚Šç‡æ¤œè¨¼

        Returns:
            True: é–¾å€¤ã‚’ã‚¯ãƒªã‚¢, False: é–¾å€¤æœªé”
        """
        self.log("\n" + "="*80)
        self.log("ã‚¹ãƒ†ãƒƒãƒ—3: æ­©ç•™ã¾ã‚Šç‡æ¤œè¨¼")
        self.log("="*80)

        df = pd.read_csv(self.TEMP_CSV)

        # å®Œå“ãƒ‡ãƒ¼ã‚¿ä»¶æ•°
        å®Œå“_count = (df['å•†å“çŠ¶æ…‹'] == 'å®Œå“').sum()
        æ­©ç•™ã¾ã‚Šç‡ = å®Œå“_count / len(df) * 100

        self.log(f"  ç·ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(df)}ä»¶")
        self.log(f"  å®Œå“ãƒ‡ãƒ¼ã‚¿: {å®Œå“_count}ä»¶")
        self.log(f"  æ­©ç•™ã¾ã‚Šç‡: {æ­©ç•™ã¾ã‚Šç‡:.1f}%")

        if æ­©ç•™ã¾ã‚Šç‡ < self.THRESHOLDS['æ­©ç•™ã¾ã‚Šç‡_æœ€å°']:
            self.log(f"\nâš ï¸ è­¦å‘Š: æ­©ç•™ã¾ã‚Šç‡ãŒä½ã„ ({æ­©ç•™ã¾ã‚Šç‡:.1f}% < {self.THRESHOLDS['æ­©ç•™ã¾ã‚Šç‡_æœ€å°']}%)")
            self.log("  â†’ ãƒ‘ãƒ¼ãƒ„ã‚„ã‚¸ãƒ£ãƒ³ã‚¯ãŒå¤šã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
            self.log("  â†’ ç¶šè¡Œã—ã¾ã™ãŒã€ã‚¿ãƒ–ç”Ÿæˆæ™‚ã«è¡¨ç¤ºãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")

        self.log("\nâœ… æ­©ç•™ã¾ã‚Šç‡æ¤œè¨¼å®Œäº†")
        return True

    def step4_regenerate_tabs(self) -> bool:
        """
        ã‚¹ãƒ†ãƒƒãƒ—4: ã‚¿ãƒ–å†ç”Ÿæˆ

        Returns:
            True: æˆåŠŸ, False: å¤±æ•—
        """
        self.log("\n" + "="*80)
        self.log("ã‚¹ãƒ†ãƒƒãƒ—4: ã‚¿ãƒ–å†ç”Ÿæˆ")
        self.log("="*80)

        # ä¸€æ™‚CSVã‚’æœ¬ç•ªCSVã«ç½®ãæ›ãˆï¼ˆã‚¿ãƒ–ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒèª­ã¿è¾¼ã‚€ï¼‰
        shutil.copy(self.TEMP_CSV, self.EXISTING_CSV)
        self.log(f"âœ“ CSVã‚’æ›´æ–°: {self.EXISTING_CSV}")

        os.chdir(self.PROJECT_DIR)

        # é§†å‹•æ–¹å¼ã‚¿ãƒ–å†ç”Ÿæˆ
        self.log("\nğŸ”§ é§†å‹•æ–¹å¼ã‚¿ãƒ–å†ç”Ÿæˆä¸­...")
        result = subprocess.run(
            ['python3', 'build_movement_tabs.py'],
            capture_output=True,
            text=True
        )
        if result.returncode != 0:
            self.log(f"âŒ é§†å‹•æ–¹å¼ã‚¿ãƒ–ã®å†ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            self.log(result.stderr)
            return False
        self.log("âœ“ é§†å‹•æ–¹å¼ã‚¿ãƒ–å®Œäº†")

        # ãƒ‘ãƒ¼ãƒ„ã‚¿ãƒ–å†ç”Ÿæˆ
        self.log("\nğŸ”§ ãƒ‘ãƒ¼ãƒ„ã‚¿ãƒ–å†ç”Ÿæˆä¸­...")
        result = subprocess.run(
            ['python3', 'build_parts_tabs.py'],
            capture_output=True,
            text=True
        )
        if result.returncode != 0:
            self.log(f"âŒ ãƒ‘ãƒ¼ãƒ„ã‚¿ãƒ–ã®å†ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            self.log(result.stderr)
            return False
        self.log("âœ“ ãƒ‘ãƒ¼ãƒ„ã‚¿ãƒ–å®Œäº†")

        self.log("\nâœ… ã‚¿ãƒ–å†ç”Ÿæˆå®Œäº†")
        return True

    def step5_commit_and_push(self, new_count: int) -> bool:
        """
        ã‚¹ãƒ†ãƒƒãƒ—5: Git commit & push

        Args:
            new_count: æ–°è¦è¿½åŠ ä»¶æ•°

        Returns:
            True: æˆåŠŸ, False: å¤±æ•—
        """
        self.log("\n" + "="*80)
        self.log("ã‚¹ãƒ†ãƒƒãƒ—5: Git commit & push")
        self.log("="*80)

        os.chdir(self.PROJECT_DIR)

        # git add
        subprocess.run(['git', 'add', 'index.html'], check=True)
        self.log("âœ“ git add index.html")

        # commit message
        date_str = datetime.now().strftime('%Y-%m-%d')
        commit_message = f"""feat: æ–°è¦æ™‚è¨ˆãƒ‡ãƒ¼ã‚¿{new_count}ä»¶ã‚’è¿½åŠ 

- æ–°è¦è¿½åŠ : {new_count}ä»¶
- é§†å‹•æ–¹å¼ã‚¿ãƒ–æ›´æ–°
- ãƒ‘ãƒ¼ãƒ„ã‚¿ãƒ–æ›´æ–°
- æ—¥ä»˜: {date_str}

ğŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>
"""

        # git commit
        subprocess.run(['git', 'commit', '-m', commit_message], check=True)
        self.log("âœ“ git commitå®Œäº†")

        # git push
        subprocess.run(['git', 'push'], check=True)
        self.log("âœ“ git pushå®Œäº†")

        self.log("\nâœ… Gitæ“ä½œå®Œäº†")
        return True

    def step6_generate_report(self, new_count: int, duplicate_count: int):
        """
        ã‚¹ãƒ†ãƒƒãƒ—6: è¨ºæ–­ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        """
        self.log("\n" + "="*80)
        self.log("ğŸ“‹ æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ")
        self.log("="*80)

        df = pd.read_csv(self.EXISTING_CSV)

        # ãƒ–ãƒ©ãƒ³ãƒ‰åˆ¥çµ±è¨ˆ
        brand_counts = df.groupby('ãƒ–ãƒ©ãƒ³ãƒ‰').size().sort_values(ascending=False).head(10)

        self.log(f"\nâœ… æˆåŠŸ: æ–°è¦ãƒ‡ãƒ¼ã‚¿{new_count}ä»¶ã‚’è¿½åŠ ")
        self.log(f"\nã€è©³ç´°ã€‘")
        self.log(f"  - æ–°è¦è¿½åŠ : {new_count}ä»¶")
        self.log(f"  - é‡è¤‡é™¤å¤–: {duplicate_count}ä»¶")
        self.log(f"  - æœ€çµ‚ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(df)}ä»¶")

        self.log(f"\nã€ãƒ–ãƒ©ãƒ³ãƒ‰åˆ¥Top10ã€‘")
        for brand, count in brand_counts.items():
            self.log(f"  - {brand}: {count}ä»¶")

        self.log(f"\nã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã€‘")
        self.log(f"  1. GitHub Pagesã¯2-5åˆ†ã§æ›´æ–°ã•ã‚Œã¾ã™")
        self.log(f"  2. å…¬é–‹URL: https://naokijodan.github.io/watch-market-analysis/")
        self.log(f"  3. æ›´æ–°ã‚’ç¢ºèªã—ã¦ãã ã•ã„")

    def run(self) -> bool:
        """
        ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ

        Returns:
            True: æˆåŠŸ, False: å¤±æ•—
        """
        try:
            # ã‚¹ãƒ†ãƒƒãƒ—1: Dry Run
            if not self.step1_dry_run():
                self.log("\nâŒ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä¸­æ–­: Dry Runå¤±æ•—")
                return False

            # ã‚¹ãƒ†ãƒƒãƒ—2: CSVãƒãƒ¼ã‚¸
            success, new_count, duplicate_count = self.step2_merge_csv()
            if not success:
                self.log("\nâŒ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä¸­æ–­: CSVãƒãƒ¼ã‚¸å¤±æ•—")
                return False

            if new_count == 0:
                self.log("\nâš ï¸ æ–°è¦ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆå…¨ã¦é‡è¤‡ï¼‰")
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                if os.path.exists(self.TEMP_CSV):
                    os.remove(self.TEMP_CSV)
                return True

            # ã‚¹ãƒ†ãƒƒãƒ—3: æ­©ç•™ã¾ã‚Šç‡æ¤œè¨¼
            if not self.step3_validate_yield_rate():
                self.log("\nâŒ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä¸­æ–­: æ­©ç•™ã¾ã‚Šç‡æ¤œè¨¼å¤±æ•—")
                # ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯
                if os.path.exists(self.TEMP_CSV):
                    os.remove(self.TEMP_CSV)
                return False

            # ã‚¹ãƒ†ãƒƒãƒ—4: ã‚¿ãƒ–å†ç”Ÿæˆ
            if not self.step4_regenerate_tabs():
                self.log("\nâŒ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä¸­æ–­: ã‚¿ãƒ–å†ç”Ÿæˆå¤±æ•—")
                # ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯
                if os.path.exists(self.BACKUP_CSV):
                    shutil.copy(self.BACKUP_CSV, self.EXISTING_CSV)
                return False

            # ã‚¹ãƒ†ãƒƒãƒ—5: Git commit & push
            if not self.step5_commit_and_push(new_count):
                self.log("\nâŒ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä¸­æ–­: Gitæ“ä½œå¤±æ•—")
                return False

            # ã‚¹ãƒ†ãƒƒãƒ—6: è¨ºæ–­ãƒ¬ãƒãƒ¼ãƒˆ
            self.step6_generate_report(new_count, duplicate_count)

            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            if os.path.exists(self.TEMP_CSV):
                os.remove(self.TEMP_CSV)

            self.log("\n" + "="*80)
            self.log("âœ… ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†")
            self.log("="*80)

            return True

        except Exception as e:
            self.log(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            self.log(traceback.format_exc())

            # ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯
            if os.path.exists(self.TEMP_CSV):
                os.remove(self.TEMP_CSV)

            return False


def main():
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python3 add_watch_data.py <new_csv_path>")
        print("ä¾‹: python3 add_watch_data.py ~/Desktop/new_seiko_2026_feb.csv")
        sys.exit(1)

    new_csv_path = sys.argv[1]

    if not os.path.exists(new_csv_path):
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {new_csv_path}")
        sys.exit(1)

    pipeline = WatchDataPipeline(new_csv_path)
    success = pipeline.run()

    sys.exit(0 if success else 1)


if __name__ == '__main__':
    main()
